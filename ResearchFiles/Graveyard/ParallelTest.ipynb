import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import torch
import gpytorch
import math
import seaborn as sns
import random
from tqdm import trange
from collections import Counter
from scipy.interpolate import splrep, interp1d
from sklearn import preprocessing
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_mll
from botorch.utils import standardize
from gpytorch.likelihoods import GaussianLikelihood, StudentTLikelihood
from gpytorch.models import ApproximateGP
from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution
from gpytorch.kernels import ScaleKernel, RBFKernel
from gpytorch.means import ConstantMean
from gpytorch.mlls import ExactMarginalLogLikelihood, VariationalELBO
import matplotlib.ticker as ticker
import matplotlib.tri as tri
import matplotlib.font_manager as font_manager
from joblib import Parallel, delayed
from sklearn.preprocessing import StandardScaler

# Check for MPS and CUDA device availability
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("MPS device found, setting as device.")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("CUDA device found, setting as device.")
else:
    device = torch.device("cpu")
    print("Neither MPS nor CUDA device found. Using default device (CPU).")


# Set the seed for all random use
def set_seeds(seed):
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    random.seed(seed)


# Define your classes and functions here...
# (Keep your STP, ExactGP, VariationalGP, TorchStandardScaler, TorchNormalizer, EI, and other functions as they are)

# Parallelization function for each campaign
def run_campaign(seed, max_or_min):
    if max_or_min == "max":
        topEGP, iterationEGP = runMaxEGP(seed)
        topSTP, iterationSTP = runMaxSTP(seed)
        topVGP, iterationVGP = runMaxVGP(seed)
    else:
        topEGP, iterationEGP = runMinEGP(seed)
        topSTP, iterationSTP = runMinSTP(seed)
        topVGP, iterationVGP = runMinVGP(seed)
    
    return (topEGP, iterationEGP), (topSTP, iterationSTP), (topVGP, iterationVGP)

# Initialize datasets and common variables
datasets = [("P3HT", "max"), ("Perovskite", "min")]
campaigns = 50

for element, max_or_min in datasets:
    print(f"Starting {element}")

    data = pd.read_csv(f"datasets/{element}_dataset.csv")
    data = data.groupby(data.columns[-1]).mean().reset_index()
    train_x = torch.tensor(data.iloc[:, 1:].values, dtype=torch.float)
    train_y = torch.tensor(data.iloc[:, 0].values, dtype=torch.float).unsqueeze(1)

    N = len(train_x)

    # We are using predefined candidates, so we can scale at the start
    TorchStd = TorchStandardScaler()
    TorchStd.fit(train_x)
    TorchNorm = TorchNormalizer()
    TorchNorm.fit(train_x)

    total_samples = len(train_y)

    set_seeds(22)

    n_top = int(math.ceil(N * 0.05))

    # Find the top 5% of the samples
    train_y_df = pd.DataFrame(train_y.numpy(), columns=[0])
    if max_or_min == "max":
        top_samples = train_y_df.nlargest(n_top, train_y_df.columns[0], keep='first').iloc[:, 0].values.tolist()
    else:
        top_samples = train_y_df.nsmallest(n_top, train_y_df.columns[0], keep='first').iloc[:, 0].values.tolist()

    print(f"Number of of top 5% samples: {len(top_samples)}")
    print(f"Top 5% samples: {top_samples}")

    def TopSamplesAmnt(y, top_samples):
        return len([i for i in y if i in top_samples]) / len(top_samples)

    # Generate a list of seeds randomly picked from the range 0-1000 equal to the number of campaigns without repeating
    seedList = random.sample(range(1000), campaigns)

    # Run campaigns in parallel
    results = Parallel(n_jobs=-1)(
        delayed(run_campaign)(seed, max_or_min) for seed in seedList
    )

    # Process the results
    topEGP_results = [result[0] for result in results]
    topSTP_results = [result[1] for result in results]
    topVGP_results = [result[2] for result in results]

    # Function to dynamically collect arrays
    def collect_arrays(results, index):
        arrays = []
        for result in results:
            arrays.append(result[index])
        return arrays

    # Function to pad arrays with the last element to match the maximum length
    def pad_array(array, max_length):
        return np.pad(array, (0, max_length - len(array)), 'constant', constant_values=array[-1])

    def find_max_length(results, index):
        arrays = collect_arrays(results, index)
        return max(len(arr[0]) for arr in arrays)

    # Process arrays for each type
    def process_arrays(results, index, max_length):
        arrays = collect_arrays(results, index)
        padded_arrays = [pad_array(arr[0], max_length) for arr in arrays]
        stack = np.stack(padded_arrays)
        mean_values = np.mean(stack, axis=0)
        std_values = np.std(stack, axis=0)
        return mean_values, std_values

    # Process arrays for STP, EGP, and VGP
    max_length_STP = find_max_length(topSTP_results, 0)
    max_length_EGP = find_max_length(topEGP_results, 0)
    max_length_VGP = find_max_length(topVGP_results, 0)
    max_length = max(max_length_STP, max_length_EGP, max_length_VGP)
    mean_topSTP, std_valuesSTP = process_arrays(topSTP_results, 0, max_length)
    mean_topEGP, std_valuesEGP = process_arrays(topEGP_results, 0, max_length)
    mean_topVGP, std_valuesVGP = process_arrays(topVGP_results, 0, max_length)

    # Ensure that the number of iterations matches the longest array length
    iterations = np.arange(1, max_length + 1)

    sns.set(style="whitegrid")
    # Plot the mean and fill between the min and max for each type
    fig = plt.figure(figsize=(16, 12), dpi=800)
    ax = plt.subplot(111)

    # Plot for STP
    ax.plot(iterations, mean_topSTP, label='Mean STP', color='blue', linewidth=2)
    ax.fill_between(iterations, mean_topSTP - std_valuesSTP, mean_topSTP + std_valuesSTP, label='STP Standard Deviation', color='blue', alpha=0.1)

    # Plot for EGP
    ax.plot(iterations, mean_topEGP, label='Mean EGP', color='orange', linewidth=2)
    ax.fill_between(iterations, mean_topEGP - std_valuesEGP, mean_topEGP + std_valuesEGP, label='EGP Standard Deviation', color='orange', alpha=0.1)

    # Plot for VGP
    ax.plot(iterations, mean_topVGP, label='Mean VGP', color='green', linewidth=2)
    ax.fill_between(iterations, mean_topVGP - std_valuesVGP, mean_topVGP + std_valuesVGP, label='VGP Standard Deviation', color='green', alpha=0.1)

    plt.xlabel('Number of Iterations', fontsize=25)
    plt.ylabel('Percentage of Top 5% Samples Found', fontsize=25)
    plt.title(f'Average Percentage of Top Samples from the {element} Dataset \n Found Over {campaigns} Campaigns Using EI', fontsize=30, pad=20)
    box = ax.get_position()
    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=20)

    # Customize ticks
    plt.xticks(fontsize=20)
    plt.yticks(fontsize=20)

    # Adjust axis limits and aspect ratio if needed
    plt.ylim(0, 100)
    plt.xlim(0, max_length)

    # Save the plot
    plt.savefig(f"EI_{element}_{campaigns}_Campaigns_{max_or_min.capitalize()}.png")
    plt.show()
